# cameras/camera_monitor.py
import cv2
import av
import time
import logging
import numpy as np
import mediapipe as mp
import traceback
from datetime import datetime

from models.alert_cooldown import AlertCooldownManager
from utils.schedule_checker import is_within_time_period, get_current_status
from utils.head_angle import calculate_head_angle
from utils.helpers import safe_mkdir, get_timestamp, uuid_suffix
from utils.uploader import upload_queue
import screeninfo

# === è­¦å ±å†·å»è¨­å®š ===
ALERT_COOLDOWNS = {
    "EYES CLOSED": 10,
    "HEAD TURNED": 10,
    "MISSING CAP": 10,
    "MISSING MASK": 10,
}


class CameraMonitor:
    def __init__(self, config, index, pose_model, maskcap_model,n_model=None):
        self.config = config
        self.camera_index = index
        self.pose_model = pose_model
        self.maskcap_model = maskcap_model
        self.n_model = n_model

        self.frame = np.ones((480, 640, 3), dtype=np.uint8)
        self.display_frame = self.frame.copy()
        self.running = True

        # ç‹€æ…‹
        self.eye_close_counter = 0
        self.head_turn_counter = 0
        self.missing_cap_count = 0
        self.missing_mask_count = 0

        # å³æ™‚æ•¸å€¼
        self.l_eye_value = 0.0
        self.r_eye_value = 0.0
        self.head_angle = 0.0
        self.face_asymmetry = 0.0
        self.side_turn_ratio = 0.0

        # ä¸²æµ
        self.use_pyav = True
        self.pyav_error_count = 0
        self.max_pyav_errors = 30

        self.cooldown_mgr = AlertCooldownManager(ALERT_COOLDOWNS)
        self.face_detector = None

    # =============================
    # ä¸²æµè®€å–
    # =============================

    def read_thread_func(self):
        if self.use_pyav:
            try:
                self.read_with_pyav()
            except Exception as e:
                logging.error(f"[{self.config['camera_id']}] PyAV ç™¼ç”ŸéŒ¯èª¤ï¼Œæ”¹ç”¨ OpenCVï¼š{e}")
                self.use_pyav = False
                self.read_with_opencv()
        else:
            self.read_with_opencv()

    def read_with_pyav(self):
        retry = 0
        while self.running:
            try:
                logging.info(f"ğŸ“¡ [PyAV] é€£ç·šæ”å½±æ©Ÿ {self.config['location']}")
                container = av.open(self.config["rtsp_url"], options={
                    "rtsp_transport": "tcp",
                    "buffer_size": "1048576",
                    "max_delay": "500000",
                    "stimeout": "5000000",
                    "flags": "low_delay",
                    "fflags": "nobuffer+fastseek",
                })
                for frame in container.decode(video=0):
                    if not self.running:
                        break
                    img = frame.to_ndarray(format="bgr24")
                    self.frame = cv2.resize(img, (640, 480))
                    time.sleep(0.03)
                container.close()
            except Exception as e:
                retry += 1
                logging.warning(f"[{self.config['camera_id']}] PyAV é€£ç·šéŒ¯èª¤ (ç¬¬{retry}æ¬¡)ï¼š{e}")
                time.sleep(3)

    def read_with_opencv(self):
        while self.running:
            cap = None
            try:
                logging.info(f"ğŸ“¡ [OpenCV] é€£ç·šæ”å½±æ©Ÿ {self.config['location']}")
                cap = cv2.VideoCapture(self.config["rtsp_url"], cv2.CAP_FFMPEG)
                cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
                cap.set(cv2.CAP_PROP_FPS, 25)

                if not cap.isOpened():
                    raise Exception("OpenCV ç„¡æ³•é–‹å•Ÿ RTSP ä¸²æµ")

                while self.running:
                    ret, frame = cap.read()
                    if not ret:
                        time.sleep(0.2)
                        continue
                    self.frame = cv2.resize(frame, (640, 480))
                    time.sleep(0.04)
            except Exception as e:
                logging.error(f"[{self.config['camera_id']}] OpenCV éŒ¯èª¤ï¼š{e}")
                time.sleep(5)
            finally:
                if cap:
                    cap.release()

    # =============================
    # ä¸»æ¨è«–æµç¨‹
    # =============================

    def process_thread_func(self):
        if self.face_detector is None:
            mp_face_mesh = mp.solutions.face_mesh
            self.face_detector = mp_face_mesh.FaceMesh(
                static_image_mode=False,
                max_num_faces=1,
                refine_landmarks=True,
                min_detection_confidence=0.5,
                min_tracking_confidence=0.5
            )
            logging.info(f"[{self.config['camera_id']}] Mediapipe åˆå§‹åŒ–å®Œæˆ")

        while self.running:
            try:
                base = self.frame.copy()
                vis = base.copy()
                self.draw_status_header(vis)

                if not is_within_time_period():
                    self.display_frame = vis
                    time.sleep(0.5)
                    continue

                # ====== MediaPipe è‡‰éƒ¨ ======
                rgb = cv2.cvtColor(base, cv2.COLOR_BGR2RGB)
                face_results = self.face_detector.process(rgb)

                has_face = face_results and face_results.multi_face_landmarks
                if has_face:
                    lm = face_results.multi_face_landmarks[0]
                    self.draw_face_landmarks(vis, lm)

                    l_eye = abs(lm.landmark[145].y - lm.landmark[159].y)
                    r_eye = abs(lm.landmark[374].y - lm.landmark[386].y)
                    self.l_eye_value = l_eye
                    self.r_eye_value = r_eye

                    eyes_closed = (
                        l_eye < self.config["eye_close_threshold"] and
                        r_eye < self.config["eye_close_threshold"]
                    )
                    if eyes_closed:
                        if not self.cooldown_mgr.is_in_cooldown(self.config["camera_id"], "EYES CLOSED"):
                            self.eye_close_counter += 1
                    else:
                        self.eye_close_counter = 0
                else:
                    # ===== è‹¥æœªåµæ¸¬åˆ°äººè‡‰ï¼ŒåŠé€æ˜æ¸…ç©ºç•«é¢ä»¥é¿å…é¬¼å½± =====
                    #vis = cv2.addWeighted(base, 0.3, np.zeros_like(base), 0.7, 0)
                    #self.reset_counters_face()
                    #self.display_frame = vis
                    #time.sleep(0.1)
                    #continue
                    self.reset_counters_face()
                    # vis ä¿æŒç‚º baseï¼ˆä¸æ”¹è®Šï¼‰

                # ====== YOLO Pose ======
                pose_results = self.pose_model(base, verbose=False)
                main_person = None
                for r in pose_results:
                    if r.keypoints is not None:
                        for kp in r.keypoints.data:
                            keypoints = kp.cpu().numpy()
                            if np.count_nonzero(keypoints[:, 2] > 0.8) >= 5:
                                main_person = keypoints
                                break
                    if main_person is not None:
                        break

                if main_person is not None:
                    self.draw_pose_keypoints(vis, main_person)
                    h_angle, asym, side = calculate_head_angle(main_person)
                    self.head_angle = h_angle or 0.0
                    self.face_asymmetry = asym or 0.0
                    self.side_turn_ratio = side or 0.0

                    head_turned = self.is_head_turned(h_angle, asym, side)
                    if head_turned:
                        if not self.cooldown_mgr.is_in_cooldown(self.config["camera_id"], "HEAD TURNED"):
                            self.head_turn_counter += 1
                    else:
                        self.head_turn_counter = 0
                else:
                    # ===== è‹¥æœªåµæ¸¬åˆ°å§¿å‹¢ï¼ŒåŠé€æ˜æ¸…ç©ºç•«é¢ä»¥é¿å…ä¸Šä¸€å¹€æ®˜ç•™ =====
                    #vis = cv2.addWeighted(base, 0.1, np.zeros_like(base), 0.7, 0)
                    #self.reset_counters_pose()
                    #self.display_frame = vis
                    # è‹¥æœªåµæ¸¬åˆ°å§¿å‹¢ï¼šä¸å†å£“æš—ç•«é¢
                    # åªé‡ç½® pose ç›¸é—œè¨ˆæ•¸ï¼Œä¿ç•™ vis ç‚ºåŸå§‹ç•«é¢ï¼Œä¹‹å¾Œç”± n_model åˆ¤å®šæ˜¯å¦ç‚º person
                    self.reset_counters_pose()

                # ============================================================
                # ğŸ§  æ”¹é€²ç‰ˆé˜²å‘†æ¢ä»¶ï¼šè‹¥æœªåµæ¸¬åˆ° person (class_id == 0)ï¼Œç›´æ¥è·³é
                # person çš„ class_id = 0ï¼Œéœ€é”åˆ°æœ€ä½ä¿¡å¿ƒå€¼æ‰ç®—æœ‰æ•ˆåµæ¸¬
                # ============================================================
                # ä½¿ç”¨ yolo11n ä½œ person gateï¼ˆè‹¥æœ‰æä¾›ï¼‰
                person_detected = False
                person_conf_thr = 0.30
                if self.n_model is not None:
                    try:
                        n_results = self.n_model(base, conf=person_conf_thr, verbose=False)
                        # åªæª¢æŸ¥ä¸¦ç¹ªè£½ person (class_id == 0)
                        person_detected = self.draw_persons(vis, n_results, conf_thr=person_conf_thr)
                        logging.debug(f"[{self.config.get('camera_id','?')}] n_model person_detected={person_detected}")
                    except Exception as e:
                        logging.warning(f"[{self.config.get('camera_id','?')}] n_model åµæ¸¬éŒ¯èª¤ï¼š{e}")
                else:
                    # fallback: ä½¿ç”¨åŸæœ¬çš„ pose-based åˆ¤å®šï¼ˆè‹¥ main_person å·²åµæ¸¬åˆ°è¦–ç‚ºæœ‰äººï¼‰
                    # è‹¥ä½ åŸæœ¬æœ‰æ›´è¤‡é›œçš„ pose åˆ¤å®šé‚è¼¯ï¼Œå¯åœ¨æ­¤ä¿ç•™/è¤‡è£½éä¾†
                    if main_person is not None:
                        person_detected = True

                if not person_detected:
                    # è‹¥æ²’æœ‰åµæ¸¬åˆ° personï¼Œç•«é¢å…ˆæŠ¼æš—ï¼Œé‡ç½®å£ç½©/å®‰å…¨å¸½è¨ˆæ•¸ä¸¦è·³éå¾ŒçºŒæª¢æ¸¬
                    vis = cv2.addWeighted(base, 0.4, np.zeros_like(base), 0.2, 0)
                    self.missing_mask_count = 0
                    self.missing_cap_count = 0
                    self.display_frame = vis
                    time.sleep(0.1)
                    continue

                # ====== YOLO Mask/Cap ======
                cap_detected = False
                mask_detected = False
                mouth_detected = False
                mask_conf = 0.0  # åˆå§‹åŒ–ä¿¡å¿ƒå€¼

                maskcap_results = self.maskcap_model(base, conf=0.25, iou=0.7, verbose=False)
                for r in maskcap_results:
                    if not hasattr(r, "boxes") or r.boxes is None:
                        continue
                    for box in r.boxes:
                        cls_id = int(box.cls[0])
                        conf = float(box.conf[0])
                        x1, y1, x2, y2 = map(int, box.xyxy[0])
                        label_name = self.maskcap_model.names[cls_id].lower()

                        # ===== é¡åˆ¥é‚è¼¯èˆ‡ä¿¡å¿ƒé–€æª» =====
                        if "cap" in label_name and conf >= 0.55:
                            cap_detected = True
                            color = (0, 255, 0)  # ç¶ è‰²
                        elif "mask" in label_name:
                            mask_detected = True
                            mask_conf = conf
                            color = (255, 255, 255)  # ç™½è‰²
                        elif "mouth" in label_name and conf >= 0.55:
                            mouth_detected = True
                            color = (0, 0, 255)  # ç´…è‰²
                        else:
                            color = (255, 255, 0)  # é»ƒè‰²ä½œç‚ºé è¨­

                        self.draw_box(vis, (x1, y1, x2, y2), f"{label_name} {conf:.2f}", color)

                # ============================================================
                # ğŸ”§ æ”¹é€²ç‰ˆé‚è¼¯ï¼šè‹¥å˜´å·´åµæ¸¬åˆ°ä¸”å£ç½©ä¿¡å¿ƒåº¦ä½ï¼Œè¦–ç‚ºã€Œæœªæˆ´å£ç½©ã€
                # ============================================================
                if mouth_detected and (not mask_detected or mask_conf < 0.8):
                    if not self.cooldown_mgr.is_in_cooldown(self.config["camera_id"], "MISSING MASK"):
                        self.missing_mask_count += 1
                else:
                    self.missing_mask_count = 0

                # ============================================================
                # ç¼ºå¸½é‚è¼¯ï¼šcap ä¿¡å¿ƒå€¼éœ€ >= 0.55 æ‰ç®—æœ‰æˆ´
                # ============================================================
                if not cap_detected:
                    if not self.cooldown_mgr.is_in_cooldown(self.config["camera_id"], "MISSING CAP"):
                        self.missing_cap_count += 1
                else:
                    self.missing_cap_count = 0


                # ====== è­¦å ±è§¸ç™¼ ======
                self.check_alerts(vis)
                self.display_frame = vis

            except Exception as e:
                logging.error(f"[{self.config['camera_id']}] æ¨è«–éŒ¯èª¤ï¼š{e}")
                logging.debug(traceback.format_exc())
            time.sleep(0.08)

    # =============================
    # é¡¯ç¤ºç•«é¢
    # =============================

    def display_thread_func(self):
        win_name = self.config["location"]

        # === Step 1. å–å¾—è¢å¹•è§£æåº¦ ===
        screen = screeninfo.get_monitors()[0]
        screen_w, screen_h = screen.width, screen.height

        # === Step 2. è‡ªå‹•è¨ˆç®—è¡Œåˆ—èˆ‡æ¯å€‹è¦–çª—å¤§å° ===
        total_cameras = self.config.get("total_cameras", 16)  # è‹¥ä¸»ç¨‹å¼å¯æä¾›ç¸½æ”å½±æ©Ÿæ•¸ï¼Œå¯å‚³å…¥æ­¤åƒæ•¸
        max_cols = min(4, total_cameras)                      # æ¯è¡Œæœ€å¤š 4 å€‹ï¼Œå¯ä¾éœ€æ±‚èª¿æ•´
        rows = (total_cameras + max_cols - 1) // max_cols     # è‡ªå‹•æ›è¡Œæ•¸
        aspect_ratio = 4 / 3                                  # ä¿æŒç›£æ§ç•«é¢æ¯”ä¾‹
        margin_x, margin_y = 10, 10                           # è¦–çª—é–“è·

        # æ¯å€‹è¦–çª—å¯¬é«˜ï¼ˆå«é‚Šè·ï¼‰
        win_w = int((screen_w - (max_cols + 1) * margin_x) / max_cols)
        win_h = int(win_w / aspect_ratio)

        # è‹¥ç¸½é«˜åº¦è¶…éè¢å¹•ï¼Œå‰‡ç¸®å°æ¯”ä¾‹
        total_height = rows * (win_h + margin_y)
        if total_height > screen_h:
            scale = screen_h / total_height
            win_w = int(win_w * scale)
            win_h = int(win_h * scale)

        # === Step 3. è¨ˆç®—ç•¶å‰æ”å½±æ©Ÿåº§æ¨™ ===
        row = self.camera_index // max_cols
        col = self.camera_index % max_cols
        x = margin_x + col * (win_w + margin_x)
        y = margin_y + row * (win_h + margin_y)

        # === Step 4. å»ºç«‹è¦–çª—ä¸¦ç§»å‹•ä½ç½® ===
        cv2.namedWindow(win_name, cv2.WINDOW_NORMAL)
        cv2.resizeWindow(win_name, win_w, win_h)
        cv2.moveWindow(win_name, x, y)

        logging.info(
            f"[{self.config['camera_id']}] é¡¯ç¤º â†’ ({x},{y}) "
            f"å¤§å° {win_w}x{win_h}, è¢å¹• {screen_w}x{screen_h}"
        )

        # === Step 5. é¡¯ç¤ºä¸»è¿´åœˆ ===
        while self.running:
            try:
                disp = self.display_frame.copy()
                self.draw_status_footer(disp)
                cv2.imshow(win_name, disp)
                if cv2.waitKey(2) & 0xFF == ord("q"):
                    self.running = False
                    break
            except Exception as e:
                logging.error(f"[{self.config['camera_id']}] é¡¯ç¤ºéŒ¯èª¤ï¼š{e}")
                time.sleep(0.2)
        cv2.destroyWindow(win_name)

    # =============================
    # è­¦å ±é‚è¼¯
    # =============================

    def check_alerts(self, annotated_frame):
        alerts = [
            ("EYES CLOSED", self.eye_close_counter, self.config["close_threshold_frames"]),
            ("HEAD TURNED", self.head_turn_counter, self.config["head_turn_frames"]),
            ("MISSING CAP", self.missing_cap_count, self.config["missing_cap_frames"]),
            ("MISSING MASK", self.missing_mask_count, self.config["missing_mask_frames"]),
        ]
        for a_type, counter, threshold in alerts:
            if counter >= threshold:
                if not self.cooldown_mgr.is_in_cooldown(self.config["camera_id"], a_type):
                    self.cooldown_mgr.update(self.config["camera_id"], a_type)
                    self.reset_counter(a_type)
                    self.take_screenshot(annotated_frame, a_type)

    def take_screenshot(self, annotated_frame, alert_type):
        date_folder = datetime.now().strftime("%Y%m%d")
        folder = f"capture/{date_folder}"
        safe_mkdir(folder)
        filename = f"{self.config['camera_id']}_{get_timestamp()}_{uuid_suffix()}_{alert_type}.png"
        path = f"{folder}/{filename}"
        cv2.imwrite(path, annotated_frame)
        logging.info(f"ğŸ“· {self.config['location']} {alert_type} æˆªåœ–å®Œæˆ â†’ {path}")
        upload_queue.put((annotated_frame.copy(), self.config, alert_type))

    # =============================
    # ç¹ªåœ–è¼”åŠ©
    # =============================

    def draw_status_header(self, img):
        status = get_current_status()
        now = datetime.now().strftime("%H:%M:%S")
        color = (0, 255, 0) if status == "WORK" else (0, 255, 255)
        cv2.rectangle(img, (440, 8), (635, 56), (0, 80, 0), -1)
        cv2.putText(img, f"Status: {status}", (448, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
        cv2.putText(img, f"Time: {now}", (448, 48), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)

    def draw_status_footer(self, img):
        cv2.putText(img, f"L_eye:{self.l_eye_value:.3f} R_eye:{self.r_eye_value:.3f}",
                    (10, 460), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)
        cv2.putText(img, f"Head:{self.head_angle:.1f}  Asym:{self.face_asymmetry:.3f}",
                    (10, 478), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)

    def draw_pose_keypoints(self, img, keypoints, conf_thr=0.5):
        skeleton_pairs = [
            (5, 7), (7, 9), (6, 8), (8, 10),
            (11, 13), (13, 15), (12, 14), (14, 16),
            (5, 6), (11, 12), (5, 11), (6, 12),
            (0, 1), (0, 2), (1, 3), (2, 4),
        ]
        for i, j in skeleton_pairs:
            if i < len(keypoints) and j < len(keypoints):
                if keypoints[i][2] > conf_thr and keypoints[j][2] > conf_thr:
                    cv2.line(img, (int(keypoints[i][0]), int(keypoints[i][1])),
                             (int(keypoints[j][0]), int(keypoints[j][1])), (0, 255, 255), 1)
        head_points = {0: "Nose", 1: "L_Eye", 2: "R_Eye", 3: "L_Ear", 4: "R_Ear"}
        for idx, name in head_points.items():
            if idx < len(keypoints) and keypoints[idx][2] > conf_thr:
                x, y = int(keypoints[idx][0]), int(keypoints[idx][1])
                cv2.circle(img, (x, y), 3, (0, 200, 255), -1)
                cv2.putText(img, name, (x + 4, y - 6), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 200, 255), 1)

    def draw_face_landmarks(self, img, landmarks):
        ih, iw = img.shape[:2]
        draw_idxs = {33, 133, 159, 145, 362, 263, 386, 374, 13, 14, 87, 317, 1, 2, 98}
        for idx, lm in enumerate(landmarks.landmark):
            if idx in draw_idxs:
                x, y = int(lm.x * iw), int(lm.y * ih)
                cv2.circle(img, (x, y), 2, (255, 160, 0), -1)

    def draw_box(self, image, box, label, color=None):
        """
        åœ¨ç•«é¢ä¸Šç¹ªè£½æ¨™è¨»æ¡†èˆ‡æ¨™ç±¤æ–‡å­—
        - cap / mouth / headï¼šæ–‡å­—é¡¯ç¤ºåœ¨æ¡†ä¸Šæ–¹
        - mask / othersï¼šæ–‡å­—é¡¯ç¤ºåœ¨æ¡†ä¸‹æ–¹
        - capï¼šç¶ è‰²æ¡† (0,255,0)
        - maskï¼šç™½è‰²æ¡† (255,255,255)
        """
        x1, y1, x2, y2 = map(int, box)
        font = cv2.FONT_HERSHEY_SIMPLEX
        scale = 0.6
        thickness = 1  # æ”¹ç‚º 1ï¼Œç¬¦åˆéœ€æ±‚
        text_color = (0, 0, 0)  # é»‘è‰²æ–‡å­—
        (w, h), _ = cv2.getTextSize(label, font, scale, thickness)

        label_lower = label.lower()

        # ===== æ¡†é¡è‰²é‚è¼¯ =====
        if "cap" in label_lower:
            color = (0, 255, 0)          # ç¶ è‰²
        elif "mask" in label_lower:
            color = (255, 255, 255)      # ç™½è‰²
        elif "mouth" in label_lower:
            color = (0, 0, 255)          # ç´…è‰²
        else:
            color = color or (0, 255, 0)  # é è¨­ä¿ç•™ç¶ è‰²ï¼ˆå¯ç”±å‘¼å«æ–¹è¦†å¯«ï¼‰

        # ===== ç¹ªè£½æ¡†ç·š =====
        cv2.rectangle(image, (x1, y1), (x2, y2), color, thickness)

        # ===== æ–‡å­—ä½ç½®é‚è¼¯ =====
        if any(k in label_lower for k in ["cap", "mouth", "head"]):
            # é¡¯ç¤ºåœ¨æ¡†ä¸Šæ–¹
            y_text = max(y1 - 5, h + 5)
        else:
            # é¡¯ç¤ºåœ¨æ¡†ä¸‹æ–¹
            y_text = min(y2 + h + 10, image.shape[0] - 5)

        # ===== èƒŒæ™¯æ–¹å¡Šï¼ˆèˆ‡æ¡†åŒè‰²ï¼‰ =====
        cv2.rectangle(image, (x1, y_text - h - 6), (x1 + w + 6, y_text), color, -1)
        cv2.putText(image, label, (x1 + 3, y_text - 4), font, scale, text_color, thickness)


    def draw_persons(self, image, n_results, conf_thr=0.30):
        """
        å¾ yolo (n_model) çš„çµæœç•«å‡º person bounding boxesï¼ˆåªç•« personï¼‰ã€‚
        åƒæ•¸:
          image: è¦ç¹ªè£½çš„å½±åƒ (æœƒå°±åœ°ç¹ªè£½)
          n_results: n_model(...) å›å‚³çš„çµæœ iterable
          conf_thr: person ä¿¡å¿ƒé–€æª»
        å›å‚³:
          bool - æ˜¯å¦è‡³å°‘åµæ¸¬åˆ°ä¸€å€‹ person
        """
        person_found = False
        if n_results is None:
            return False
        for r in n_results:
            if not hasattr(r, "boxes") or r.boxes is None:
                continue
            for box in r.boxes:
                try:
                    # å…¼å®¹ tensor/list å‹æ…‹
                    cls_val = box.cls
                    conf_val = box.conf
                    cls_id = int(cls_val[0]) if hasattr(cls_val, "__len__") else int(cls_val)
                    conf = float(conf_val[0]) if hasattr(conf_val, "__len__") else float(conf_val)
                except Exception:
                    continue

                # åªè™•ç† person class_id == 0
                if cls_id != 0 or conf < conf_thr:
                    continue

                # å–å¾— xyxy åº§æ¨™
                try:
                    xy = box.xyxy[0]
                    if hasattr(xy, "cpu"):
                        xy = xy.cpu().numpy()
                    x1, y1, x2, y2 = map(int, xy)
                except Exception:
                    # è‹¥ç„¡æ³•å–å¾—åº§æ¨™ï¼Œç•¥éæ­¤ box
                    continue

                # ç•«æ¡†èˆ‡æ¨™ç±¤ï¼šperson æ”¹ç‚ºé»ƒè‰² (BGR: 0,255,255)
                label = f"person {conf:.2f}"
                self.draw_box(image, (x1, y1, x2, y2), label, color=(0, 255, 255))
                person_found = True
        return person_found

    def draw_n_results(self, image, n_results, conf_thr=0.30):
        """
        æŠŠ yolo11n (n_model) å›å‚³çš„æ‰€æœ‰åµæ¸¬é …ç›®ç¹ªè£½åˆ° imageã€‚
        - æœƒé¡¯ç¤º <label> <conf>ï¼Œä¸¦ç”¨ä¸åŒé¡è‰²å€åˆ† class idã€‚
        - è¿”å›ç¹ªè£½çš„ç¸½ box æ•¸é‡ï¼ˆå¯ç”¨æ–¼åˆ¤æ–·æ˜¯å¦æœ‰åµæ¸¬åˆ°ä»»ä½•ç‰©ä»¶ï¼‰ã€‚
        """
        if n_results is None:
            return 0

        # å–å¾— class name å­—å…¸ï¼ˆè‹¥ n_model æœ‰æä¾›ï¼‰
        names = {}
        if hasattr(self, "n_model") and self.n_model is not None:
            names = getattr(self.n_model, "names", None) or getattr(getattr(self.n_model, "model", None), "names", {}) or {}

        # ç°¡å–® paletteï¼Œæœƒæ ¹æ“š class id å–æ¨¡
        palette = [
            (255,  80,  80), ( 80,255,  80), ( 80, 80,255), (255,255, 80),
            (255, 80,255), ( 80,255,255), (200,120, 70), (120,200, 70),
            (70,120,200), (200, 70,120)
        ]

        drawn = 0
        for r in n_results:
            if not hasattr(r, "boxes") or r.boxes is None:
                continue
            for box in r.boxes:
                try:
                    cls_val = box.cls
                    conf_val = box.conf
                    cls_id = int(cls_val[0]) if hasattr(cls_val, "__len__") else int(cls_val)
                    conf = float(conf_val[0]) if hasattr(conf_val, "__len__") else float(conf_val)
                except Exception:
                    continue

                if conf < conf_thr:
                    continue

                # å–å¾—åæ¨™ (å„ªå…ˆ xyxyï¼Œå¦å‰‡ç”¨ xywh è½‰æ›)
                try:
                    if hasattr(box, "xyxy"):
                        xy = box.xyxy[0]
                        if hasattr(xy, "cpu"):
                            xy = xy.cpu().numpy()
                        x1, y1, x2, y2 = map(int, xy)
                    elif hasattr(box, "xywh"):
                        arr = box.xywh[0]
                        if hasattr(arr, "cpu"):
                            arr = arr.cpu().numpy()
                        cx, cy, w, h = arr
                        x1 = int(cx - w / 2); y1 = int(cy - h / 2)
                        x2 = int(cx + w / 2); y2 = int(cy + h / 2)
                    else:
                        continue
                except Exception:
                    continue

                label = names.get(cls_id, str(cls_id))
                text = f"{label} {conf:.2f}"
                color = palette[cls_id % len(palette)]
                # ä½¿ç”¨æ—¢æœ‰ draw_boxï¼ˆæœƒç¹ªè£½æ¨™ç±¤èƒŒæ™¯ï¼‰ï¼Œå‚³ color ä»¥è¦†å¯«é è¨­
                self.draw_box(image, (x1, y1, x2, y2), text, color=color)
                drawn += 1

        return drawn

    def reset_counter(self, alert_type):
        if alert_type == "EYES CLOSED":
            self.eye_close_counter = 0
        elif alert_type == "HEAD TURNED":
            self.head_turn_counter = 0
        elif alert_type == "MISSING CAP":
            self.missing_cap_count = 0
        elif alert_type == "MISSING MASK":
            self.missing_mask_count = 0

    def reset_counters_face(self):
        self.eye_close_counter = 0

    def reset_counters_pose(self):
        self.head_turn_counter = 0

    def is_head_turned(self, angle, asym, side):
        turned = 0
        total = 0
        if angle is not None:
            total += 1
            if abs(angle) > 25:
                turned += 1
        if asym is not None:
            total += 1
            if abs(asym) > 0.15:
                turned += 1
        if side is not None:
            total += 1
            if abs(side) > 0.4:
                turned += 1
        return turned >= 2 if total >= 2 else abs(angle or 0) > 35
